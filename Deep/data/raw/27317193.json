{
     "PMID": "27317193",
     "OWN": "NLM",
     "STAT": "MEDLINE",
     "DCOM": "20180117",
     "LR": "20180117",
     "IS": "1549-5485 (Electronic) 1072-0502 (Linking)",
     "VI": "23",
     "IP": "7",
     "DP": "2016 Jul",
     "TI": "Active Inference, epistemic value, and vicarious trial and error.",
     "PG": "322-38",
     "LID": "10.1101/lm.041780.116 [doi]",
     "AB": "Balancing habitual and deliberate forms of choice entails a comparison of their respective merits-the former being faster but inflexible, and the latter slower but more versatile. Here, we show that arbitration between these two forms of control can be derived from first principles within an Active Inference scheme. We illustrate our arguments with simulations that reproduce rodent spatial decisions in T-mazes. In this context, deliberation has been associated with vicarious trial and error (VTE) behavior (i.e., the fact that rodents sometimes stop at decision points as if deliberating between choice alternatives), whose neurophysiological correlates are \"forward sweeps\" of hippocampal place cells in the arms of the maze under consideration. Crucially, forward sweeps arise early in learning and disappear shortly after, marking a transition from deliberative to habitual choice. Our simulations show that this transition emerges as the optimal solution to the trade-off between policies that maximize reward or extrinsic value (habitual policies) and those that also consider the epistemic value of exploratory behavior (deliberative or epistemic policies)-the latter requiring VTE and the retrieval of episodic information via forward sweeps. We thus offer a novel perspective on the optimality principles that engender forward sweeps and VTE, and on their role on deliberate choice.",
     "CI": [
          "(c) 2016 Pezzulo et al.; Published by Cold Spring Harbor Laboratory Press."
     ],
     "FAU": [
          "Pezzulo, Giovanni",
          "Cartoni, Emilio",
          "Rigoli, Francesco",
          "Pio-Lopez, Leo",
          "Friston, Karl"
     ],
     "AU": [
          "Pezzulo G",
          "Cartoni E",
          "Rigoli F",
          "Pio-Lopez L",
          "Friston K"
     ],
     "AUID": [
          "ORCID: http://orcid.org/0000-0001-6813-8282"
     ],
     "AD": "Institute of Cognitive Sciences and Technologies, National Research Council, 00185 Rome, Italy giovanni.pezzulo@istc.cnr.it. Institute of Cognitive Sciences and Technologies, National Research Council, 00185 Rome, Italy La Sapienza University of Rome, Rome, 00185 Italy. The Wellcome Trust Centre for Neuroimaging, UCL, London WC1N 3BG, United Kingdom. Pascal Institute, Clermont University, 63000 Clermont-Ferrand, France. The Wellcome Trust Centre for Neuroimaging, UCL, London WC1N 3BG, United Kingdom.",
     "LA": [
          "eng"
     ],
     "GR": [
          "091593/Wellcome Trust/United Kingdom"
     ],
     "PT": [
          "Journal Article"
     ],
     "DEP": "20160617",
     "PL": "United States",
     "TA": "Learn Mem",
     "JT": "Learning & memory (Cold Spring Harbor, N.Y.)",
     "JID": "9435678",
     "SB": "IM",
     "MH": [
          "Animals",
          "Bayes Theorem",
          "*Decision Making",
          "Humans",
          "Maze Learning",
          "*Models, Psychological",
          "Rats",
          "*Reward"
     ],
     "PMC": "PMC4918783",
     "EDAT": "2016/06/19 06:00",
     "MHDA": "2018/01/18 06:00",
     "CRDT": [
          "2016/06/19 06:00"
     ],
     "PHST": [
          "2016/01/25 00:00 [received]",
          "2016/04/12 00:00 [accepted]",
          "2016/06/19 06:00 [entrez]",
          "2016/06/19 06:00 [pubmed]",
          "2018/01/18 06:00 [medline]"
     ],
     "AID": [
          "23/7/322 [pii]",
          "10.1101/lm.041780.116 [doi]"
     ],
     "PST": "epublish",
     "SO": "Learn Mem. 2016 Jun 17;23(7):322-38. doi: 10.1101/lm.041780.116. Print 2016 Jul.",
     "term": "place cells"
}