{
     "PMID": "26888174",
     "OWN": "NLM",
     "STAT": "PubMed-not-MEDLINE",
     "DCOM": "20160817",
     "LR": "20170220",
     "IS": "2045-2322 (Electronic) 2045-2322 (Linking)",
     "VI": "6",
     "DP": "2016 Feb 18",
     "TI": "Recurrent Spiking Networks Solve Planning Tasks.",
     "PG": "21142",
     "LID": "10.1038/srep21142 [doi]",
     "AB": "A recurrent spiking neural network is proposed that implements planning as probabilistic inference for finite and infinite horizon tasks. The architecture splits this problem into two parts: The stochastic transient firing of the network embodies the dynamics of the planning task. With appropriate injected input this dynamics is shaped to generate high-reward state trajectories. A general class of reward-modulated plasticity rules for these afferent synapses is presented. The updates optimize the likelihood of getting a reward through a variant of an Expectation Maximization algorithm and learning is guaranteed to convergence to a local maximum. We find that the network dynamics are qualitatively similar to transient firing patterns during planning and foraging in the hippocampus of awake behaving rats. The model extends classical attractor models and provides a testable prediction on identifying modulating contextual information. In a real robot arm reaching and obstacle avoidance task the ability to represent multiple task solutions is investigated. The neural planning method with its local update rules provides the basis for future neuromorphic hardware implementations with promising potentials like large data processing abilities and early initiation of strategies to avoid dangerous situations in robot co-worker scenarios.",
     "FAU": [
          "Rueckert, Elmar",
          "Kappel, David",
          "Tanneberg, Daniel",
          "Pecevski, Dejan",
          "Peters, Jan"
     ],
     "AU": [
          "Rueckert E",
          "Kappel D",
          "Tanneberg D",
          "Pecevski D",
          "Peters J"
     ],
     "AD": "Intelligent Autonomous Systems Lab, Technische Universitat Darmstadt, 64289, Germany. Institute for Theoretical Computer Science, Technische Universitat Graz, 8020, Austria. Intelligent Autonomous Systems Lab, Technische Universitat Darmstadt, 64289, Germany. Institute for Theoretical Computer Science, Technische Universitat Graz, 8020, Austria. Intelligent Autonomous Systems Lab, Technische Universitat Darmstadt, 64289, Germany. Robot Learning Group, Max-Planck Institute for Intelligent Systems, Tuebingen, 72076, Germany.",
     "LA": [
          "eng"
     ],
     "PT": [
          "Journal Article",
          "Research Support, Non-U.S. Gov't"
     ],
     "DEP": "20160218",
     "PL": "England",
     "TA": "Sci Rep",
     "JT": "Scientific reports",
     "JID": "101563288",
     "PMC": "PMC4758071",
     "EDAT": "2016/02/19 06:00",
     "MHDA": "2016/02/19 06:01",
     "CRDT": [
          "2016/02/19 06:00"
     ],
     "PHST": [
          "2015/09/30 00:00 [received]",
          "2015/12/18 00:00 [accepted]",
          "2016/02/19 06:00 [entrez]",
          "2016/02/19 06:00 [pubmed]",
          "2016/02/19 06:01 [medline]"
     ],
     "AID": [
          "srep21142 [pii]",
          "10.1038/srep21142 [doi]"
     ],
     "PST": "epublish",
     "SO": "Sci Rep. 2016 Feb 18;6:21142. doi: 10.1038/srep21142.",
     "term": "hippocampus"
}