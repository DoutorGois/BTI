Based on a large body of neurophysiological, neuroanatomical, and behavioral data, it has been suggested that the hippocampal formation serves as a spatial learning and localization system. This spatial representation is metric in nature and arises as a result of associations between sensory inputs and dead-reckoning information generated by the animal. However, despite the fact that these two information streams provide uncertain information (e.g., recognition errors, dead-reckoning drifts, etc.), the hippocampal computational models suggested to date have not explicitly addressed information fusion from erroneous sources. In this paper we develop a computational model of hippocampal spatial learning and relate its functioning to a probabilistic tool used for uncertain sensory fusion in robots: the Kalman filter. This parallel allows us to derive statistically optimal update expressions for the localization performed by our computational model.