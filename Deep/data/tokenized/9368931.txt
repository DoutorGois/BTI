This paper explores the hypothesis that various subregions (but by no means all) of the posterior parietal cortex are specialized to process visual information to extract a variety of affordances for behaviour. Two biologically based models of regions of the posterior parietal cortex of the monkey are introduced. The model of the lateral intraparietal area (LIP) emphasizes its roles in dynamic remapping of the representation of targets during a double saccade task, and in combining stored, updated input with current visual input. The model of the anterior intraparietal area (AIP) addresses parietal-premotor interactions involved in grasping, and analyses the interaction between the AIP and premotor area F5. The model represents the role of other intraparietal areas working in concert with the inferotemporal cortex as well as with corollary discharge from F5 to provide and augment the affordance information in the AIP, and suggests how various constraints may resolve the action opportunities provided by multiple affordances. Finally, a systems-level model of hippocampo parietal interactions underlying rat navigation is developed, motivated by the monkey data used in developing the above two models as well as by data on neurones in the posterior parietal cortex of the monkey that are sensitive to visual motion. The formal similarity between dynamic remapping (primate saccades) and path integration (rat navigation) is noted, and certain available data on rat posterior parietal cortex in terms of affordances for locomotion are explained. The utility of further modelling, linking the World Graph model of cognitive maps for motivated behaviour with hippocampal-parietal interactions involved in navigation, is also suggested. These models demonstrate that posterior parietal cortex is not only itself a network of interacting subsystems, but functions through cooperative computation with many other brain regions.