Intelligent action entails exploiting predictions about associations between elements of ones environment. The hippocampus and mediotemporal cortex are endowed with the network topology, physiology, and neurochemistry to automatically and sparsely code sensori-cognitive associations that can be reconstructed from single or partial inputs. Whilst acquiring fMRI data and performing an attentional task, participants were incidentally presented with a sequence of cartoon images. By assigning subjects a post-scan free-association task on the same images we assayed the density of associations triggered by these stimuli. Using multivariate Bayesian decoding, we show that human hippocampal and temporal neocortical structures host sparse associative representations that are automatically triggered by visual input. Furthermore, as predicted theoretically, there was a significant increase in sparsity in the Cornu Ammonis subfields, relative to the entorhinal cortex. Remarkably, the sparsity of CA encoding correlated significantly with associative memory performance over subjects; elsewhere within the temporal lobe, entorhinal, parahippocampal, perirhinal and fusiform cortices showed the highest model evidence for the sparse encoding of associative density. In the absence of reportability or attentional confounds, this charts a distribution of visual associative representations within hippocampal populations and their temporal lobe afferent fields, and demonstrates the viability of retrospective associative sampling techniques for assessing the form of reflexive associative encoding.