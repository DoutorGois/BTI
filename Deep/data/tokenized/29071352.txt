Virtual environments (VE) allow testing complex behaviors in naturalistic settings by combining highly controlled visual stimuli with spatial navigation and other cognitive tasks. They also allow for the recording of eye movements using high-precision eye tracking techniques, which is important in electrophysiological studies examining the response properties of neurons in visual areas of nonhuman primates. However, during virtual navigation, the pattern of retinal stimulation can be highly dynamic which may influence eye movements. Here we examine whether and how eye movement patterns change as a function of dynamic visual stimulation during virtual navigation tasks, relative to standard oculomotor tasks. We trained two rhesus macaques to use a joystick to navigate in a VE to complete two tasks. To contrast VE behavior with classic measurements, the monkeys also performed a simple Cued Saccade task. We used a robust algorithm for rapid classification of saccades, fixations, and smooth pursuits. We then analyzed the kinematics of saccades during all tasks, and specifically during different phases of the VE tasks. We found that fixation to smooth pursuit ratios were smaller in VE tasks (4:5) compared to the Cued Saccade task (7:1), reflecting a more intensive use of smooth pursuit to foveate targets in VE than in a standard visually guided saccade task or during spontaneous fixations. Saccades made to rewarded targets (exploitation) tended to have increased peak velocities compared to saccades made to unrewarded objects (exploration). VE exploitation saccades were 6% slower than saccades to discrete targets in the Cued Saccade task. Virtual environments represent a technological advance in experimental design for nonhuman primates. Here we provide a framework to study the ways that eye movements change between and within static and dynamic displays.