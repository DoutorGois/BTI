Multiple sensory-motor maps located in the brainstem and the cortex are involved in spatial orientation. Guiding movements of eyes, head, neck and arms they provide an approximately linear relation between target distance and motor response. This involves especially the superior colliculus in the brainstem and the parietal cortex. There, the natural frame of reference follows from the retinal representation of the environment. A model of navigation is presented that is based on the modulation of activity in those sensory-motor maps. The actual mechanism chosen was gain-field modulation, a process of multimodal integration that has been demonstrated in the parietal cortex and superior colliculus, and was implemented as attraction to visual cues (colour). Dependent on the metric of the sensory-motor map, the relative attraction to these cues implemented as gain field modulation and their position define a fixed point attractor on the plane for locomotive behaviour. The actual implementation used Kohonen-networks in a variant of reinforcement learning that are well suited to generate such topographically organized sensory-motor maps with roughly linear visuo-motor response characteristics. In the following, it was investigated how such an implicit coding of target positions by gain-field parameters might be represented in the hippocampus formation and under what conditions a direction-invariant space representation can arise from such retinotopic representations of multiple cues. Information about the orientation in the plane--as could be provided by head direction cells--appeared to be necessary for unambiguous space representation in our model in agreement with physiological experiments. With this information, Gauss-shaped "place-cells" could be generated, however, the representation of the spatial environment was repetitive and clustered and single cells were always tuned to the gain-field parameters as well.